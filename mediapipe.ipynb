{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a9625-a8db-45bb-9572-6bbb8d8a98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3daed-1d0b-46cb-b00f-de43cf71b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O deeplabv3.tflite -q https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a72030-c72b-465d-ab00-01fc9c4a12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65de323-4692-4253-b801-1bf3bb0b24bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary modules.\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python.components import processors\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9abe876-b824-4af2-bc27-87cbf62d221c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from matplotlib import pyplot as plt\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "from mediapipe.python.solutions.drawing_utils import DrawingSpec\n",
    "\n",
    "def zoom_and_crop(image, landmarks, scale=2.5, output_size=224):\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Convert normalized landmarks to pixel coordinates\n",
    "    landmark_px = np.array([[lm.x * w, lm.y * h] for lm in landmarks])\n",
    "\n",
    "    # Bounding box around landmarks\n",
    "    min_xy = landmark_px.min(axis=0)\n",
    "    max_xy = landmark_px.max(axis=0)\n",
    "    center = (min_xy + max_xy) / 2\n",
    "    size = max(max_xy - min_xy) * scale  # square region with padding\n",
    "\n",
    "    top_left = center - size / 2\n",
    "    bottom_right = center + size / 2\n",
    "\n",
    "    x1, y1 = np.clip(top_left, 0, [w, h]).astype(int)\n",
    "    x2, y2 = np.clip(bottom_right, 0, [w, h]).astype(int)\n",
    "\n",
    "\n",
    "    cropped = image[y1:y2, x1:x2]\n",
    "    cropped = cv2.resize(cropped, (output_size, output_size))\n",
    "\n",
    "    return cropped\n",
    "\n",
    "video_path = \"SourceVideos/J46.mp4\"\n",
    "output_npy = \"Images_Keypoints/letter_J46_sequence.npy\"\n",
    "sequence = []\n",
    "SEQUENCE_LENGTH = 30  \n",
    "\n",
    "BaseOptions = python.BaseOptions\n",
    "HandLandmarker = vision.HandLandmarker\n",
    "HandLandmarkerOptions = vision.HandLandmarkerOptions\n",
    "HandLandmarkerResult = vision.HandLandmarkerResult\n",
    "VisionRunningMode = vision.RunningMode\n",
    "\n",
    "drawing_utils = mp.solutions.drawing_utils\n",
    "drawing_styles = mp.solutions.drawing_styles\n",
    "hand_connections = mp.solutions.hands.HAND_CONNECTIONS\n",
    "\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='hand_landmarker.task'),\n",
    "    running_mode=VisionRunningMode.VIDEO,\n",
    "    num_hands=2\n",
    ")\n",
    "\n",
    "with HandLandmarker.create_from_options(options) as landmarker:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    timestamp = 0\n",
    "    frame_id = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "\n",
    "        # Detect hand\n",
    "        result = landmarker.detect_for_video(mp_image, timestamp)\n",
    "\n",
    "        if result.hand_landmarks:\n",
    "            # Store flattened landmark list (x, y, z)\n",
    "            flat_landmarks = [coord for lm in result.hand_landmarks[0] for coord in (lm.x, lm.y, lm.z)]\n",
    "            sequence.append(flat_landmarks)\n",
    "\n",
    "           \n",
    "            landmark_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "            for lm in result.hand_landmarks[0]:\n",
    "                landmark_proto.landmark.add(x=lm.x, y=lm.y, z=lm.z)\n",
    "\n",
    "            drawing_utils.draw_landmarks(\n",
    "                frame,\n",
    "                landmark_proto,\n",
    "                hand_connections,\n",
    "                landmark_drawing_spec=DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),\n",
    "                connection_drawing_spec=DrawingSpec(color=(255, 255, 255), thickness=1)\n",
    "            )\n",
    "\n",
    "            cropped_hand = zoom_and_crop(frame, result.hand_landmarks[0], output_size=224)\n",
    "\n",
    "        \n",
    "            os.makedirs(\"images_keypoints\", exist_ok=True)\n",
    "            cv2.imwrite(f\"images_keypoints/J46_{frame_id}.jpg\", cropped_hand)\n",
    "            frame_id += 1\n",
    "\n",
    "    \n",
    "        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.pause(0.001)\n",
    "        plt.clf()\n",
    "\n",
    "        timestamp += int(1000 / cap.get(cv2.CAP_PROP_FPS)) \n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if sequence:\n",
    "    os.makedirs(os.path.dirname(output_npy), exist_ok=True)\n",
    "    np.save(output_npy, np.array(sequence[:SEQUENCE_LENGTH]))\n",
    "    print(f\"Saved {min(SEQUENCE_LENGTH, len(sequence))} frames to {output_npy}\")\n",
    "else:\n",
    "    print(\"No hand landmarks were detected :(\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276dcff2-3b23-4abd-b3a8-138cbfb37254",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CREATING IMAGES WITH BLACK BACKGROUND + LANDMARKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e734d-cc7a-4356-bba9-03dc07ff0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import mediapipe as mp\n",
    "\n",
    "# Set roots and other params\n",
    "video_root = \"RawVideos\"\n",
    "output_root = \"DynamicLetters_BlackBG\"\n",
    "image_size = 224\n",
    "frames_per_video = 10\n",
    "allowed_exts = [\".mp4\", \".mov\", \".MOV\"]\n",
    "\n",
    "# Setup MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Go through Videos\n",
    "for split in [\"Train\", \"Test\"]:\n",
    "    split_path = os.path.join(video_root, split)\n",
    "\n",
    "    for file in sorted(os.listdir(split_path)):\n",
    "        if not any(file.endswith(ext) for ext in allowed_exts):\n",
    "            continue\n",
    "\n",
    "        label = file[0].upper()\n",
    "        video_id = os.path.splitext(file)[0]\n",
    "        video_path = os.path.join(split_path, file)\n",
    "        save_dir = os.path.join(output_root, split, label, video_id)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        detected_frames = []\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(frame_rgb)\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                black = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    drawing.draw_landmarks(black, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "\n",
    "                detected_frames.append(black)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # Randomly sample and save up to 10 frames\n",
    "        selected_frames = random.sample(detected_frames, min(frames_per_video, len(detected_frames)))\n",
    "        for i, frame in enumerate(selected_frames):\n",
    "            out_path = os.path.join(save_dir, f\"{video_id}_{i}.jpg\")\n",
    "            cv2.imwrite(out_path, frame)\n",
    "\n",
    "        print(f\"{video_id} â†’ {len(selected_frames)} frames saved in {save_dir}\")\n",
    "\n",
    "hands.close()\n",
    "print(\"All videos processed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
